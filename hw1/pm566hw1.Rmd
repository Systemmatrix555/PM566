---
title: "PM 566 Assignment 1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Chris Hanson
## September 24, 2021
#  
### In this assignment I am given the task of determining whether daily concentration of PM2.5 has decreased in California in the last 15 years. To do this I am using data provided by the U.S. EPA.
<br>
<br>
```{r, message = FALSE}
rm(list = ls())

# Load libraries
library(tidyverse)
library(data.table)
library(janitor)
library(leaflet)
library(ggplot2)

```


### **Problem 1.** _Read in the data. Check dimensions, headers, footers, variable names, and variable types. Check for any data issues, particularly in the key variables. Summarize all findings._
```{r load and check data}
# Read in the data using data.table().
pm2004 <- data.table::fread("ad_viz_plotval_data_2004.csv")
pm2004 <- clean_names(pm2004)
pm2019 <- data.table::fread("ad_viz_plotval_data_2019.csv")
pm2019 <- clean_names(pm2019)
# Check dimensions
paste("The 2004 dataset has", dim(pm2004)[1], "observations and", dim(pm2004)[2], "variables.")
paste("The 2019 dataset has", dim(pm2019)[1], "observations and", dim(pm2019)[2], "variables.")

# Check headers
head(pm2004)
head(pm2019)

# Check footers
tail(pm2004)
tail(pm2019)

# Check variable names
paste(colnames(pm2004))

# Check variable types
sapply(pm2004, typeof)

# Check for issues in key variables:
str(pm2004) # General readout
summary(pm2004) #Summary statistics
summary(pm2004$daily_mean_pm2_5_concentration) #Key variable
mean(is.na(pm2004$daily_mean_pm2_5_concentration)) #No missing values
hist(pm2004$daily_mean_pm2_5_concentration, breaks = 100, xlim=c(0,100)) #Check for outliers

str(pm2019) # General readout
summary(pm2019) #Summary statistics
summary(pm2019$daily_mean_pm2_5_concentration) #Key variable
mean(is.na(pm2019$daily_mean_pm2_5_concentration)) #No missing values
hist(pm2019$daily_mean_pm2_5_concentration, breaks = 100, xlim=c(0,100)) #Check for outliers

```

Summary of findings: 
While the Max values of PM 2.5 in each of these data sets is extremely high, they don't seem to be errors - just extreme events.


### **Problem 2.** _Combine the two years of data into one data frame. Use the Date variable to create a new column for year, which will serve as an identifier. Change the names of the key variables so that they are easier to refer to in your code._

```{r combine and clean data}
# Combine the two years of data into one data frame.
pm <- rbind(pm2004, pm2019)

# Use the Date variable to create a new column for year, which will serve as an identifier.
dates <- pm$date
dates2 <- as.POSIXct(dates, format = "%m/%d/%Y")
dates3 <- format(dates2, format="%Y") 

pm <-  mutate(pm, year = dates3) #New column "year" added

# Change the names of the key variables so that they are easier to refer to in your code.
pm <- rename(pm, pm25 = daily_mean_pm2_5_concentration)

pm$year <- as.numeric(pm$year) #so that colorNumeric works, but can instead use colorFactor

```

### **Problem 3.** _Create a basic map in leaflet() that shows the locations of the sites (make sure to use different colors for each year). Summarize the spatial distribution of the monitoring sites._

```{r}
# Create a basic map in leaflet() that shows the locations of the sites (make sure to use different colors for each year).
pal <- colorNumeric(palette = "RdYlBu", domain=c(2004, 2019)) 
#colorNumeric doesn't work any more

leaflet(pm) %>%
  addProviderTiles('OpenStreetMap') %>% 
  addCircles(lat=~site_latitude,lng=~site_longitude, color=pal(pm$year), opacity=1, fillOpacity=1, radius=100)
  #addLegend('bottomleft', pal=pal, values=~c(2004, 2019),
          #title='Site Locations', opacity=1)
    #this legend is driving me crazy

```

Summarize the spatial distribution of the monitoring sites: ???

### **Problem 4.** _Check for any missing or implausible values of PM2.5 in the combined data set. Explore the proportions of each and provide a summary of any temporal patterns you see in these observations._

```{r}
# Check for any missing or implausible values of PM2.5 in the combined data set.
mean(is.na(pm))
mean(is.na(pm$cbsa_code))
mean(is.na(pm$cbsa_code))/mean(is.na(pm))
# 0.36% of all data is missing, and 7.5% of the "cbsa_code" data is missing. As 7.5 is 21x greater than 0.36, and there are 21 variables, that means all missing data is from the "cbsa_code" column.
# ---------------------------------------------------------------------------
# Extreme values
boxplot(pm$daily_aqi_value)
summary(pm$daily_aqi_value)
#Here we see an extreme outlier of AQI = 301. According to airnow.gov, an AQI (air quality index) of 301 or higher represents an emergency condition. This value is most associated with wildfires, which is not unreasonable.

boxplot(pm$pm25)
summary(pm$pm25)
# PM 2.5 has an extremely high Max value of 251, perhaps this is associated with the same wildfire event observed in the high AQI event discovered above:
pm[which(grepl(251, pm$pm25)), daily_aqi_value]
#The extreme PM2.5 and AQI values did indeed come from the same reading, suggesting they are both accurate readings of an extreme weather event.
# ---------------------------------------------------------------------------
# Explore the proportions of each and provide a summary of any temporal patterns you see in these observations.

# calc ave PM2.5 by site
pm_ave <- pm %>% group_by(site_id) %>% summarize(mean25 = mean(pm25))
# find the highest average pm2.5 value
max(pm_ave$mean25)
#which index of pm_ave has this max average value?
high_site_index = which(pm_ave$mean25 %in% max(pm_ave$mean25))
#what is the site id associated with this max value?
high_site = pm_ave$site_id[high_site_index]
#let's graph pm25 at this site in 2004
pmhigh_2004 <- filter(pm, site_id == high_site, year == 2004)
ggplot(data = pmhigh_2004, aes(x=date, y=pm25)) +
  geom_line()


```

### **Problem 5.** _Explore the main question of interest at three different spatial levels. Create exploratory plots (e.g. boxplots, histograms, line plots) and summary statistics that best suit each level of data. Be sure to write up explanations of what you observe in these data._
_State_
_County_
_Site in Los Angeles_
