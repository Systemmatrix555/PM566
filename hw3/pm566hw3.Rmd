---
title: "PM 566 HW 3"
author: "Chris Hanson"
date: "11/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, error = FALSE)
```

```{r, message = FALSE}
library(httr)
library(xml2)
library(stringr)
library(tidyverse)
library(data.table)
library(tidytext)
library(ggplot2)
```

# 1. APIs

### Using the NCBI API, look for papers that show up under the term "sars-cov-2 trial vaccine." Look for the data in the PubMed database, and then retrieve the details of the paper (as shown in lab 7), including the PubMed IDs.

```{r}

# Accessing the PubMed database through the NCBI API and searching for "sars-cov-2 trial  vaccine".  
query_ids <- GET(
  url = "https://eutils.ncbi.nlm.nih.gov/",
  path = "entrez/eutils/esearch.fcgi",
  query = list(db = "pubmed",
               term = "sars-cov-2 trial vaccine",
               retmax = 10000)
)

ids <- content(query_ids)

ids <- as.character(ids)

ids <- str_extract_all(ids, "<Id>[[:digit:]]+</Id>")[[1]]

ids <- str_remove_all(ids, "<Id>|</Id>")
```

I found `r length(ids)` papers.

Using the list of Pubmed IDs retrieved, download each paper's details using the query parameter rettype = abstract. Keep just the first 250.

```{r}
publications <- GET(
  url   = "https://eutils.ncbi.nlm.nih.gov/",
  path = "entrez/eutils/efetch.fcgi",
  query = list(
    db = "pubmed",
    id = I(paste(ids[1:250], collapse=",")),
    retmax = 10000,
    rettype = "abstract"
    )
)

# Extracting the content of the results of GET into an XML object:
publications <- httr::content(publications)

# Turning this XML object into characters:
publications_txt <- as.character(publications)
```

Create a dataset containing the following:

PubMed ID number

Title of the paper

Name of the journal where it was published

Publication date

Abstract of the paper

```{r}
pub_char_list <- xml_children(publications)
pub_char_list <- sapply(pub_char_list, as.character)

abstracts <- str_extract(pub_char_list, "<Abstract>[[:print:][:space:]]+</Abstract>")
abstracts <- str_remove_all(abstracts, "</?[[:alnum:]- =\"]+.")
abstracts <- str_replace_all(abstracts, "[[:space:]]+", " ")

titles <- str_extract(pub_char_list, "<ArticleTitle>[[:print:][:space:]]+</ArticleTitle>")
titles <- str_remove_all(titles, "</?[[:alnum:]- =\"]+>")

journals <- str_extract(pub_char_list, "<Title>[[:print:][:space:]]+</Title>")
journals <- str_remove_all(journals, "</?[[:alnum:]- =\"]+>")

#dates <- str_extract(pub_char_list, "<PubDate>[[:print:][:space:]]+</PubDate>")
dates <- str_extract(pub_char_list, "<DateRevised>[[:print:][:space:]]+</DateRevised>")
dates <- str_remove_all(dates, "</?[[:alnum:]- =\"]+>")
dates <- str_replace_all(dates, "[[:space:]]+", " ")
dates <- trimws(dates, which = c("both"))
dates <- format(as.Date(dates, "%Y %m %d"), "%m/%d/%Y")
dates[1:10]


database <- data.frame(
  PubMedId = ids[1:250],
  Title    = titles,
  Journal  = journals,
  Date     = dates,
  Abstract = abstracts
)
knitr::kable(database[1:5,], caption = "Covid19 Vaccine Trial")
```

# 2. Text Mining

###  A dataset from the course data repository contains 3241 abstracts from articles across 5 search terms. Analyse these abstracts to find interesting insights.

Tokenize the abstracts and count the number of each token. 

```{r, message = FALSE}
# Importing the dataset 
mining_abstracts <- read_csv("pubmed.csv")
mining_abstracts <- as_tibble(mining_abstracts)

# Discovering the 5 topics of the abstracts provided
terms <- mining_abstracts %>%
  count(term) %>%
  arrange(desc(n))

# Tokenize the abstracts and count the number of each token--------------------

# All abstracts, stop words not removed
mining_abstracts %>%
  unnest_tokens(output = word, input = abstract) %>%
  count(word, sort = TRUE) %>%
  top_n(10) %>%
  knitr::kable()

# All abstracts, stop words and numbers removed
tokens <- mining_abstracts %>%
  unnest_tokens(output = word, input = abstract) %>%
  count(word, sort = TRUE) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!grepl(pattern = "^[0-9]+$", x = word))
  
tokens %>%  
  top_n(10) %>%
  knitr::kable()

# Tokenizing per search term----------------------------------------------------

tokens2 <- mining_abstracts %>%
  unnest_tokens(output = word, input = abstract) %>%
  count(word, term, sort = TRUE) %>%
  anti_join(stop_words, by = "word") %>%
  filter(!grepl(pattern = "^[0-9]+$", x = word))

# Covid abstracts
tokens2 %>%
  filter(term == "covid") %>%
  top_n(5) %>%
  knitr::kable()

# Cystic fibrosis abstracts
tokens2 %>%
  filter(term == "cystic fibrosis") %>%
  top_n(5) %>%
  knitr::kable()

# Meningitis abstracts
tokens2 %>%
  filter(term == "meningitis") %>%
  top_n(5) %>%
  knitr::kable()

# Preeclampsia abstracts
tokens2 %>%
  filter(term == "preeclampsia") %>%
  top_n(5) %>%
  knitr::kable()

# Prostate cancer abstracts
tokens2 %>%
  filter(term == "prostate cancer") %>%
  top_n(5) %>%
  knitr::kable()
```

Tokenize the abstracts into bigrams. Find the 10 most common bigrams and visualize them with ggplot2.

```{r}
mining_abstracts %>%
  unnest_ngrams(output = bigram, input = abstract, n = 2) %>%
  count(bigram, sort = TRUE) %>%
  top_n(10) %>%
  ggplot(aes(x = n, y = fct_reorder(bigram, n))) +
  geom_col()
```

Calculate the TF-IDF value for each word-search term combination (the search term is the "document"). What are the 5 tokens from each search term with the highest TF-IDF value? How are the results different from the answers from question 1?

(TF-IDF is term frequency x inverse document frequency, it's a measure of how unique a term is to a single document)

```{r}

tfidf <- mining_abstracts %>%
  unnest_tokens(output = word, input = abstract) %>%
  count(word, term) %>%
  bind_tf_idf(word, term, n) %>%
  arrange(desc(tf_idf))

tfidf %>%
  filter(term == "covid") %>%
  top_n(5) %>%
  knitr::kable()

tfidf %>%
  filter(term == "cystic fibrosis") %>%
  top_n(5) %>%
  knitr::kable()

tfidf %>%
  filter(term == "meningitis") %>%
  top_n(5) %>%
  knitr::kable()

tfidf %>%
  filter(term == "preeclampsia") %>%
  top_n(5) %>%
  knitr::kable()

tfidf %>%
  filter(term == "prostate cancer") %>%
  top_n(5) %>%
  knitr::kable()
```

For the COVID abstracts, the top used words and the top TF-IDF shared 3 of 5 words.

For the cystic fibrosis abstracts, the top used words and the top TF-IDF shared 3 of 5 words.

For the meningitis abstracts, the top used words and the top TF-IDF shared 3 of 5 words.

For the preeclampsia abstracts, the top used words and the top TF-IDF shared 3 of 5 words.

For the prostate cancer abstracts, the top used words and the top TF-IDF shared 1 of 5 words.


