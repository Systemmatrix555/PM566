---
title: "PM566 Lab 7"
author: "Chris Hanson"
date: "10/8/2021"
output: 
  github_document:
    html_preview: false
  html_document: default
always_allow_html: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Lab description: Using the NCBI (National Center for Biotechnology Information) API to make queries and extract information using XML and regular expressions.

## Question 1: How many results are provided on PubMed when searching sars-cov-2?

```{r how many}
# Downloading the website using XML
website <- xml2::read_html("https://pubmed.ncbi.nlm.nih.gov/?term=sars-cov-2")

# Finding the counts
#The XPath was found by right clicking the area of the website of which we wanted to see the html code and clicking "inspect," then right clicking on that code and copying full Xpath. We then search the html code for this Xpath.
counts <- xml2::xml_find_first(website, "/html/body/main/div[9]/div[2]/div[2]/div[1]/span")

# "counts" is currently an {html_node}. Turning it into text:
counts <- as.character(counts)
#"counts" is currently: "<span class=\"value\">114,846</span>"

# Extracting the data using regex.
#stringr is a tidyverse regex package.
#[0-9] is any number in the range 0-9, + means one or more matches, and we also include a comma.
stringr::str_extract(counts, "[0-9,]+") #This is our final answer
```


## Question 2: Academic publications on COVID19 and Hawaii

```{r}
library(httr)
query_ids <- GET(
  url   = "https://eutils.ncbi.nlm.nih.gov/",
  path  = "entrez/eutils/esearch.fcgi",
  query = list(db = "pubmed", 
               term = "covid19 hawaii", 
               retmax = 1000
               )
)

# Extracting the content of the response of GET
ids <- httr::content(query_ids)
```

## Question 3: Get details about the articles

```{r}
ids_list <- xml2::as_list(ids)
  
  # Turn the result into a character vector
ids <- as.character(ids)

# Find all the ids 
ids <- stringr::str_extract_all(ids, "<Id>[[:digit:]]+</Id>")[[1]]

# Remove all the leading and trailing <Id> </Id>. Make use of "|"
ids <- stringr::str_remove_all(ids, "<Id>|</Id>")
```

```{r}
publications <- GET(
  url   = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi",
  query = list(
    db = "pubmed",
    id = I(paste(ids, collapse=",")),
    retmax = 1000,
    rettype = "abstract"
    )
)

# Turning the output into character vector
publications <- httr::content(publications)
publications_txt <- as.character(publications)
```

Question 4: Distribution of universities, schools, and departments

```{r}
library(stringr)

institution <- str_extract_all(
  str_to_lower(publications_txt),
  "university\\s+of\\s+(southern|new|the)?\\s*[[:alpha:]-]+|\\s+institute\\s+of\\s+(southern|new|the)?\\s*[[:alpha:]-]+"
  ) 
institution <- unlist(institution)
table(institution)
```

I'll do the school later.

Question 5: Form a database

```{r}
pub_char_list <- xml2::xml_children(publications)
pub_char_list <- sapply(pub_char_list, as.character)

#
abstracts <- str_extract(pub_char_list, "<Abstract>[[:print:][:space:]]+</Abstract>")
abstracts <- str_remove_all(abstracts, "</?[[:alnum:]- =\"]+.")
abstracts <- str_replace_all(abstracts, "[[:space:]]+", " ")

titles <- str_extract(pub_char_list, "<ArticleTitle>[[:print:][:space:]]+</ArticleTitle>")
titles <- str_remove_all(titles, "</?[[:alnum:]- =\"]+>")

database <- data.frame(
  "[DATA TO CONCATENATE]"
)
knitr::kable(database)
```


